{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 기본코드\n",
    "import inspect\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from mmcv import Config\n",
    "from mmseg.datasets import build_dataloader, build_dataset\n",
    "from mmseg.models import build_segmentor\n",
    "from mmseg.apis import single_gpu_test\n",
    "from mmcv.runner import load_checkpoint, load_state_dict\n",
    "from mmcv.parallel import MMDataParallel\n",
    "\n",
    "def uniform_soup(cfg, model, checkpoint_paths ,device = \"cpu\", by_name = False):\n",
    "    try:\n",
    "        import torch\n",
    "    except:\n",
    "        print(\"If you want to use 'Model Soup for Torch', please install 'torch'\")\n",
    "        return model\n",
    "    \n",
    "    dataset = build_dataset(cfg.data.val)\n",
    "    data_loader = build_dataloader(\n",
    "            dataset,\n",
    "            samples_per_gpu=1,\n",
    "            workers_per_gpu=cfg.data.workers_per_gpu,\n",
    "            dist=False,\n",
    "            shuffle=False)  \n",
    "    \n",
    "    \n",
    "    model = model.to(device)\n",
    "    model_dict = model.state_dict()\n",
    "    soups = {key:[] for key in model_dict}\n",
    "    checkpoint = {}\n",
    "    for i, checkpoint_path in enumerate(checkpoint_paths):\n",
    "        checkpoint = load_checkpoint(model, checkpoint_path, map_location='cpu')\n",
    "        weight_dict = checkpoint['state_dict']\n",
    "        for k, v in weight_dict.items():\n",
    "            soups[k].append(v)\n",
    "    if 0 < len(soups):\n",
    "        soups = {k:(torch.sum(torch.stack(v), axis = 0) / len(v)).type(v[0].dtype) for k, v in soups.items() if len(v) != 0}\n",
    "        model_dict.update(soups)\n",
    "        model.load_state_dict(model_dict)\n",
    "    \n",
    "    load_state_dict(model, model_dict)\n",
    "    model.CLASSES = dataset.CLASSES\n",
    "    model = MMDataParallel(model.cuda(), device_ids=[0])\n",
    "    output = single_gpu_test(model, data_loader)\n",
    "    eval_kwargs = {}\n",
    "    eval_kwargs.update(metric=['mIoU'])\n",
    "    metric = dataset.evaluate(output, **eval_kwargs)\n",
    "    print(f\"mIoU: {metric['mIoU']}\")\n",
    "    \n",
    "    return model, checkpoint\n",
    "\n",
    "def greedy_soup(cfg, model_ori, checkpoint_paths, device = \"cpu\"):\n",
    "    try:\n",
    "        import torch\n",
    "    except:\n",
    "        print(\"If you want to use 'Model Soup for Torch', please install 'torch'\")\n",
    "        return model_ori\n",
    "    \n",
    "    dataset = build_dataset(cfg.data.val)\n",
    "    data_loader = build_dataloader(\n",
    "            dataset,\n",
    "            samples_per_gpu=1,\n",
    "            workers_per_gpu=cfg.data.workers_per_gpu,\n",
    "            dist=False,\n",
    "            shuffle=False)  \n",
    "    \n",
    "    \n",
    "    result = []\n",
    "    checkpoint = {}\n",
    "    for i, checkpoint_path in enumerate(checkpoint_paths):\n",
    "        model = model_ori.to(device)\n",
    "        checkpoint = load_checkpoint(model, checkpoint_path, map_location='cpu')\n",
    "        model.CLASSES = dataset.CLASSES\n",
    "        model = MMDataParallel(model.cuda(), device_ids=[0])\n",
    "        output = single_gpu_test(model, data_loader)\n",
    "        eval_kwargs = {}\n",
    "        eval_kwargs.update(metric=['mIoU'])\n",
    "        metric = dataset.evaluate(output, **eval_kwargs)\n",
    "        result.append((metric['mIoU'],checkpoint_path))\n",
    "        print(f\"리스트에 {i}번째 mIoU {metric['mIoU']}저장\")\n",
    "    \n",
    "    result.sort(key = lambda x : x[0], reverse = True)\n",
    "    print(f\"리스트 정렬\")\n",
    "    print(result)\n",
    "    \n",
    "    model = model_ori.to(device)\n",
    "    model_dict = model.state_dict()\n",
    "    pre_metric_value = 0\n",
    "    pre_weight_dict = {}\n",
    "    for i, (mIoU, checkpoint_path) in enumerate(result):\n",
    "        model = model_ori.to(device)\n",
    "        soups = {key:[] for key in model_dict}\n",
    "        now_model_dict = model_dict\n",
    "        if i == 0:\n",
    "            checkpoint = load_checkpoint(model, checkpoint_path, map_location='cpu')\n",
    "            pre_metric_value = mIoU\n",
    "            pre_weight_dict = checkpoint['state_dict']\n",
    "            print(\"soup 모델에 가장 높은 mIou를 가진 checkpoint가 추가되었습니다\")\n",
    "            print(f\"추가된 checkpoint_path: {checkpoint_path}\")\n",
    "            print(f\"현재 최고 mIoU: {pre_metric_value}\")\n",
    "        else:\n",
    "            checkpoint = load_checkpoint(model, checkpoint_path, map_location='cpu')\n",
    "            weight_dict = checkpoint['state_dict']\n",
    "            \n",
    "            for k, v in pre_weight_dict.items():\n",
    "                soups[k].append(v)\n",
    "            for k, v in weight_dict.items():\n",
    "                soups[k].append(v)    \n",
    "            if 0 < len(soups):\n",
    "                soups = {k:(torch.sum(torch.stack(v), axis = 0) / len(v)).type(v[0].dtype) for k, v in soups.items() if len(v) != 0}\n",
    "                now_model_dict.update(soups)\n",
    "                \n",
    "                \n",
    "            load_state_dict(model, now_model_dict)\n",
    "            model.CLASSES = dataset.CLASSES\n",
    "            model = MMDataParallel(model.cuda(), device_ids=[0])\n",
    "            output = single_gpu_test(model, data_loader)\n",
    "            eval_kwargs = {}\n",
    "            eval_kwargs.update(metric=['mIoU'])\n",
    "            metric = dataset.evaluate(output, **eval_kwargs)\n",
    "            \n",
    "            if metric['mIoU'] >= pre_metric_value:\n",
    "                pre_metric_value = metric['mIoU']\n",
    "                pre_weight_dict = now_model_dict\n",
    "                print(\"soup 모델에 새로운 checkpoint가 추가되었습니다\")\n",
    "                print(f\"추가된 checkpoint_path: {checkpoint_path}\")\n",
    "                print(f\"현재 최고 mIoU: {pre_metric_value}\")\n",
    "            else:\n",
    "                print(\"이번 체크 포인트는 soup 모델에 추가되지 않았습니다\")\n",
    "                print(f\"이번 checkpoint_path: {checkpoint_path}\")\n",
    "                print(f\"현재 최고 mIoU: {pre_metric_value}, 이번 mIou {metric['mIoU']}\")\n",
    "            \n",
    "    model = model_ori.to(device)\n",
    "    load_state_dict(model, pre_weight_dict)\n",
    "    return model, checkpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. 모델 & checkpoint 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/ml/input/code/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:235: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "################ model cfg path 적기 ################\n",
    "cfg= Config.fromfile('/opt/ml/input/code/mmsegmentation/configs/_cv07_/upernet_beit-large_fp32_8x1_640x640_160k_ade20k_final2.py')\n",
    "################ model cfg path 적기 ################\n",
    "model = build_segmentor(cfg.model)\n",
    "\n",
    "################ soup할 checkpoint path 적기 ################\n",
    "checkpoint_paths = [\n",
    "    '/opt/ml/input/code/mmsegmentation/work_dirs/upernet_beit-large_fp32_8x1_640x640_160k_ade20k_final2/epoch_8.pth',\n",
    "    '/opt/ml/input/code/mmsegmentation/work_dirs/upernet_beit-large_fp32_8x1_640x640_160k_ade20k_final2/epoch_9.pth',\n",
    "    '/opt/ml/input/code/mmsegmentation/work_dirs/upernet_beit-large_fp32_8x1_640x640_160k_ade20k_final2/epoch_10.pth',\n",
    "]\n",
    "################ soup할 checkpoint path 적기 ################\n",
    "device = \"cpu\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. uniform soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-05 06:49:59,861 - mmseg - INFO - Loaded 1 images\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Uniform Soup]\n",
      "load checkpoint from local path: /opt/ml/input/code/mmsegmentation/work_dirs/upernet_beit-large_fp32_8x1_640x640_160k_ade20k_final2/epoch_8.pth\n",
      "load checkpoint from local path: /opt/ml/input/code/mmsegmentation/work_dirs/upernet_beit-large_fp32_8x1_640x640_160k_ade20k_final2/epoch_9.pth\n",
      "load checkpoint from local path: /opt/ml/input/code/mmsegmentation/work_dirs/upernet_beit-large_fp32_8x1_640x640_160k_ade20k_final2/epoch_10.pth\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 1/1, 0.8 task/s, elapsed: 1s, ETA:     0sper class results:\n",
      "\n",
      "+---------------+-------+-------+\n",
      "|     Class     |  IoU  |  Acc  |\n",
      "+---------------+-------+-------+\n",
      "|   Backgroud   |  89.3 | 95.08 |\n",
      "| General trash |  0.0  |  nan  |\n",
      "|     Paper     |  0.0  |  nan  |\n",
      "|   Paper pack  |  nan  |  nan  |\n",
      "|     Metal     |  nan  |  nan  |\n",
      "|     Glass     | 67.01 | 99.95 |\n",
      "|    Plastic    | 41.46 | 41.68 |\n",
      "|   Styrofoam   |  nan  |  nan  |\n",
      "|  Plastic bag  | 23.69 | 23.87 |\n",
      "|    Battery    |  nan  |  nan  |\n",
      "|    Clothing   |  nan  |  nan  |\n",
      "+---------------+-------+-------+\n",
      "Summary:\n",
      "\n",
      "+-------+-------+-------+\n",
      "|  aAcc |  mIoU |  mAcc |\n",
      "+-------+-------+-------+\n",
      "| 80.12 | 36.91 | 65.14 |\n",
      "+-------+-------+-------+\n",
      "mIoU: 0.3691\n"
     ]
    }
   ],
   "source": [
    "################ save dir path 적기 ################\n",
    "save_dir_path = '/opt/ml/input/code/mmsegmentation/work_dirs/upernet_beit-large_fp32_8x1_640x640_160k_ade20k_final2/'\n",
    "\n",
    "print(\"\\n[Uniform Soup]\")\n",
    "uniform_model, checkpoint = uniform_soup(cfg, model, checkpoint_paths, device = device)\n",
    "uniform_dict = checkpoint\n",
    "uniform_dict['state_dict'] = uniform_model.state_dict()\n",
    "\n",
    "torch.save(uniform_dict, save_dir_path+f'uniform_model_soup.pth')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Greedy Soup (uniform weight update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-04 14:23:33,866 - mmseg - INFO - Loaded 324 images\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Greedy Soup (uniform weight update)]\n",
      "load checkpoint from local path: /opt/ml/input/code/mmsegmentation/work_dirs/upernet_beit-large_fp32_8x1_640x640_160k_ade20k_final/epoch_16.pth\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 324/324, 1.1 task/s, elapsed: 304s, ETA:     0sper class results:\n",
      "\n",
      "+---------------+-------+-------+\n",
      "|     Class     |  IoU  |  Acc  |\n",
      "+---------------+-------+-------+\n",
      "|   Backgroud   | 96.95 | 98.41 |\n",
      "| General trash | 43.06 |  50.3 |\n",
      "|     Paper     | 81.54 | 93.48 |\n",
      "|   Paper pack  | 71.14 |  74.2 |\n",
      "|     Metal     | 37.63 | 53.94 |\n",
      "|     Glass     | 88.14 | 95.21 |\n",
      "|    Plastic    | 63.27 | 78.59 |\n",
      "|   Styrofoam   | 82.89 | 87.94 |\n",
      "|  Plastic bag  | 87.47 | 94.81 |\n",
      "|    Battery    | 85.37 | 99.97 |\n",
      "|    Clothing   | 83.05 |  89.4 |\n",
      "+---------------+-------+-------+\n",
      "Summary:\n",
      "\n",
      "+-------+-------+------+\n",
      "|  aAcc |  mIoU | mAcc |\n",
      "+-------+-------+------+\n",
      "| 94.97 | 74.59 | 83.3 |\n",
      "+-------+-------+------+\n",
      "리스트에 0번째 mIoU 0.7459저장\n",
      "load checkpoint from local path: /opt/ml/input/code/mmsegmentation/work_dirs/upernet_beit-large_fp32_8x1_640x640_160k_ade20k_final/epoch_17.pth\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 324/324, 1.0 task/s, elapsed: 314s, ETA:     0sper class results:\n",
      "\n",
      "+---------------+-------+-------+\n",
      "|     Class     |  IoU  |  Acc  |\n",
      "+---------------+-------+-------+\n",
      "|   Backgroud   | 97.04 | 98.54 |\n",
      "| General trash | 45.48 | 52.52 |\n",
      "|     Paper     | 82.37 |  95.3 |\n",
      "|   Paper pack  | 72.96 | 80.22 |\n",
      "|     Metal     | 40.68 | 49.59 |\n",
      "|     Glass     | 87.88 | 94.06 |\n",
      "|    Plastic    | 67.21 | 83.51 |\n",
      "|   Styrofoam   | 85.15 | 95.99 |\n",
      "|  Plastic bag  | 87.03 | 92.16 |\n",
      "|    Battery    | 91.19 | 99.64 |\n",
      "|    Clothing   | 75.45 | 80.48 |\n",
      "+---------------+-------+-------+\n",
      "Summary:\n",
      "\n",
      "+-------+-------+-------+\n",
      "|  aAcc |  mIoU |  mAcc |\n",
      "+-------+-------+-------+\n",
      "| 95.21 | 75.68 | 83.82 |\n",
      "+-------+-------+-------+\n",
      "리스트에 1번째 mIoU 0.7568저장\n",
      "load checkpoint from local path: /opt/ml/input/code/mmsegmentation/work_dirs/upernet_beit-large_fp32_8x1_640x640_160k_ade20k_final/epoch_18.pth\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 324/324, 1.0 task/s, elapsed: 314s, ETA:     0sper class results:\n",
      "\n",
      "+---------------+-------+-------+\n",
      "|     Class     |  IoU  |  Acc  |\n",
      "+---------------+-------+-------+\n",
      "|   Backgroud   | 96.88 | 98.73 |\n",
      "| General trash | 51.35 | 56.81 |\n",
      "|     Paper     | 83.21 | 94.58 |\n",
      "|   Paper pack  | 67.76 | 73.24 |\n",
      "|     Metal     | 38.53 | 52.58 |\n",
      "|     Glass     | 88.17 | 96.57 |\n",
      "|    Plastic    | 74.22 | 82.04 |\n",
      "|   Styrofoam   |  83.1 | 88.96 |\n",
      "|  Plastic bag  | 88.31 | 94.43 |\n",
      "|    Battery    | 89.99 | 99.81 |\n",
      "|    Clothing   | 86.03 | 91.84 |\n",
      "+---------------+-------+-------+\n",
      "Summary:\n",
      "\n",
      "+-------+-------+-------+\n",
      "|  aAcc |  mIoU |  mAcc |\n",
      "+-------+-------+-------+\n",
      "| 95.56 | 77.05 | 84.51 |\n",
      "+-------+-------+-------+\n",
      "리스트에 2번째 mIoU 0.7705저장\n",
      "리스트 정렬\n",
      "[(0.7705, '/opt/ml/input/code/mmsegmentation/work_dirs/upernet_beit-large_fp32_8x1_640x640_160k_ade20k_final/epoch_18.pth'), (0.7568, '/opt/ml/input/code/mmsegmentation/work_dirs/upernet_beit-large_fp32_8x1_640x640_160k_ade20k_final/epoch_17.pth'), (0.7459, '/opt/ml/input/code/mmsegmentation/work_dirs/upernet_beit-large_fp32_8x1_640x640_160k_ade20k_final/epoch_16.pth')]\n",
      "load checkpoint from local path: /opt/ml/input/code/mmsegmentation/work_dirs/upernet_beit-large_fp32_8x1_640x640_160k_ade20k_final/epoch_18.pth\n",
      "soup 모델에 가장 높은 mIou를 가진 checkpoint가 추가되었습니다\n",
      "추가된 checkpoint_path: /opt/ml/input/code/mmsegmentation/work_dirs/upernet_beit-large_fp32_8x1_640x640_160k_ade20k_final/epoch_18.pth\n",
      "현재 최고 mIoU: 0.7705\n",
      "load checkpoint from local path: /opt/ml/input/code/mmsegmentation/work_dirs/upernet_beit-large_fp32_8x1_640x640_160k_ade20k_final/epoch_17.pth\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 324/324, 1.0 task/s, elapsed: 314s, ETA:     0sper class results:\n",
      "\n",
      "+---------------+-------+-------+\n",
      "|     Class     |  IoU  |  Acc  |\n",
      "+---------------+-------+-------+\n",
      "|   Backgroud   |  96.9 | 98.62 |\n",
      "| General trash | 49.16 | 55.26 |\n",
      "|     Paper     | 83.09 | 94.86 |\n",
      "|   Paper pack  | 71.78 | 78.02 |\n",
      "|     Metal     | 41.31 | 52.24 |\n",
      "|     Glass     | 87.73 | 95.35 |\n",
      "|    Plastic    | 71.39 | 82.24 |\n",
      "|   Styrofoam   | 86.55 |  94.8 |\n",
      "|  Plastic bag  | 87.97 | 93.88 |\n",
      "|    Battery    | 90.42 | 99.77 |\n",
      "|    Clothing   | 78.99 | 84.33 |\n",
      "+---------------+-------+-------+\n",
      "Summary:\n",
      "\n",
      "+-------+-------+-------+\n",
      "|  aAcc |  mIoU |  mAcc |\n",
      "+-------+-------+-------+\n",
      "| 95.47 | 76.85 | 84.49 |\n",
      "+-------+-------+-------+\n",
      "이번 체크 포인트는 soup 모델에 추가되지 않았습니다\n",
      "이번 checkpoint_path: /opt/ml/input/code/mmsegmentation/work_dirs/upernet_beit-large_fp32_8x1_640x640_160k_ade20k_final/epoch_17.pth\n",
      "현재 최고 mIoU: 0.7705, 이번 mIou 0.7685\n",
      "load checkpoint from local path: /opt/ml/input/code/mmsegmentation/work_dirs/upernet_beit-large_fp32_8x1_640x640_160k_ade20k_final/epoch_16.pth\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 324/324, 1.9 task/s, elapsed: 174s, ETA:     0sper class results:\n",
      "\n",
      "+---------------+-------+-------+\n",
      "|     Class     |  IoU  |  Acc  |\n",
      "+---------------+-------+-------+\n",
      "|   Backgroud   | 97.04 | 98.66 |\n",
      "| General trash | 46.54 |  52.3 |\n",
      "|     Paper     | 82.94 | 94.35 |\n",
      "|   Paper pack  |  76.2 | 83.15 |\n",
      "|     Metal     | 38.53 | 54.39 |\n",
      "|     Glass     | 89.49 | 96.38 |\n",
      "|    Plastic    | 70.88 |  80.7 |\n",
      "|   Styrofoam   | 83.76 | 88.91 |\n",
      "|  Plastic bag  | 88.35 | 95.06 |\n",
      "|    Battery    | 87.47 | 99.94 |\n",
      "|    Clothing   | 85.37 |  91.6 |\n",
      "+---------------+-------+-------+\n",
      "Summary:\n",
      "\n",
      "+-------+-------+-------+\n",
      "|  aAcc |  mIoU |  mAcc |\n",
      "+-------+-------+-------+\n",
      "| 95.47 | 76.96 | 85.04 |\n",
      "+-------+-------+-------+\n",
      "이번 체크 포인트는 soup 모델에 추가되지 않았습니다\n",
      "이번 checkpoint_path: /opt/ml/input/code/mmsegmentation/work_dirs/upernet_beit-large_fp32_8x1_640x640_160k_ade20k_final/epoch_16.pth\n",
      "현재 최고 mIoU: 0.7705, 이번 mIou 0.7696\n"
     ]
    }
   ],
   "source": [
    "print(\"[Greedy Soup (uniform weight update)]\")\n",
    "greedy_model, checkpoint = greedy_soup(cfg, model, checkpoint_paths, device = device)\n",
    "greedy_dict = checkpoint\n",
    "greedy_dict['state_dict'] = greedy_model.state_dict()\n",
    "torch.save(greedy_dict, save_dir_path+f'greedy_model_soup_{name}.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
